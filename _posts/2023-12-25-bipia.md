---
layout: post
title:  "Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models"
date:   2023-12-25 22:21:59 +00:00
image: /images/bipia.png
categories: research
author: "Jingwei Yi"
authors: "<strong>Jingwei Yi*</strong>, Yueqi Xie*, Bin Zhu, Keegan Hines, Emre Kiciman, Guangzhong Sun, Xing Xie, Fangzhao Wu"
venue: "arXiv"
paper: https://arxiv.org/abs/2312.14197
code: https://github.com/microsoft/BIPIA
---
We systematically evaluate the robustness of LLMs to indirect prompt injection attacks and propose several defense techniques to mitigate the risks.