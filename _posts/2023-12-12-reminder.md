---
layout: post
title:  "Self-Reminders: Defending ChatGPT against Jailbreak Attack via Self-Reminders"
date:   2023-12-12 22:21:59 +00:00
image: /images/self-reminder.png
categories: research
author: "Jingwei Yi"
authors: "Yueqi Xie*, <strong>Jingwei Yi*</strong>, Jiawei Shao, Justin Curl, Lingjuan Lyu, Qifeng Chen, Xing Xie, Fangzhao Wu"
venue: "Nature Machine Intelligence"
paper: https://www.nature.com/articles/s42256-023-00765-8
code: https://github.com/yjw1029/Self-Reminder
---
We draw inspiration from the psychological concept of self-reminders and further propose system-mode self-reminder to defend against Jailbreak attacks.